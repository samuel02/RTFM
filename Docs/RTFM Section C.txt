Section C) The RTFM-cOOre language
----------------------------------
The RTFM-cOOre language has been designed to fulfil the following goals:
- Providing a light-weight OO model for concurrent programming
- Ease of analysis, allowing for fully static and specialized implementation
- Ease of extention, e.g., w.r.t
  - inheritance (currently no inheritance)
  - type systems (currently untyped)
  - functional expression layer (currently imperative)

In the following we will describe the syntax and semantics of RTFM-cOOre 
language by a set of examples. Currently the language is limited to the 
following grammar:

A) Syntax (subset in EBNF like form)

coore: 
  | classDef*
        
classDef:
  | "class" ID "<" classArgs ">" "{" classDecl* "}"              
  
classArgs:
  | classArg ("," classArgs)*
    
classArg:
  | pType ID                                                 
  | pType "(" mSig ")" ID                                     
    
mSig:
  | pType ("," mSig)*                      
  
classDecl:
  | pType ID ":=" expr ";"   
  | ID "<" params ">" ID  ";"
  | pType ID "(" mArgs ")" "{" stmt* "}" 
  | "Task" ID "(" mArgs ")" "{" stmt* "}"
  | "Reset" "{" stmt* "}"                                      
  | "Idle" "{" stmt* "}"                                      
    
mArgs:
  | mArg ("," mArgs)*
  
mArg:
  | pType ID                                                
    
pType:
  | INT | CHAR | BOOL | BYTE | VOID                                                       
     
params:
  | expr ("," params)*                        
    
expr:                                                        
  | "async" after? before? ids "(" params ")"    (* async expression *)
  | ids LP params RP                             (* id expression    *)
  | ids LP params RP                             (* sync expresion   *)
  | INTVAL                                       (* integer value    *)
  | CHARVAL                                      (* character value  *)
  | BOOLVAL                                      (* boolean value    *)
  | "RT_rand" "(" expr ")"                       (* RT built ins     *)
  | "RT_getc" "(" ")"                                            

ids:
  | ID "." ID                                                
  | ID                                                       

after:
  | "after" time                              

before:
  | "before" time          

time:
  | INTVAL tunit?

tuint:
  | "us" | "ms" | "s"   

As seen the language currenlty provides a simpleistic expression layer 
(without any operations besides a few built ins as a proof of concept).
Also the set of statements is very limited (no conditionals, etc.)

Extending the -cOOre language with a resonable set of operations (on
primitive types), and conditionals, along with approprite type checking will
be the challenge to student of the Compiler Construction course during
the period September 1st till November 1st 2014.

However, already today the -cOOre languge is operational and the principles
can be demonstrated, as shown in the following set of examples.

The examples are design such to match those we visited in Section A) and
basically replicate the same (or similar) funcitonality in -cOOre.

Let us start by looking at the CEx1.coore:
-------------------------------------------------------------------------------
// CEx1.coore
// Per Lindgren (C) 2014
//
// Simple example

class Root<> { 
    Task t1 () {
        RT_printf("task1\n");
    }      

    Reset {
        RT_printf("User reset\n");
        async t1 ();
    } 
}
-------------------------------------------------------------------------------
Any meaningful -cOOre program must give a Root class declaration, defining
either Reset or Idle (or both).

Currenlty Tasks can only be defined within the context of a class defintion, 
to this end we use the Root class for the defintion of the Task t.

Conceptually an instance (object) of the Root class (and all its inner objects)
is created by the envirnoment when the system is "born". From an implementation
standpoint, this is done aleady by the the rtfm-core compiler, which fully
instantiates and specialises the generated -core code. Hence no objects are
created during execution of the system!

The program is complete and can be compiled (rtfm-coore->rtfm-core->gcc ...)
giving us an executable.

Let us look at the next example CEx2.coore:
-------------------------------------------------------------------------------
// CEx2.coore
// Per Lindgren (C) 2014
//
// Simple example

class Root<> { 
    Task t1 (char c) {
        RT_printf("t1 : you entered : %c\n", c);
        async after 5 s before 100 ms t2(c); // we have no operations on char yet
    }      
    
    Task t2 (char c) {
        RT_printf("t2: the same character is %c\n", c);
    }

    Reset {
        RT_printf("User reset\n");
    }
     
    Idle {
        RT_printf("enter a character (before 5s)\n");
        char c := RT_getc();
        async before 5 s t1 (c);
    }
}
-------------------------------------------------------------------------------
Here we demonstrate the use of Reset (for setup) and Idle (for background
job(s) during run-time). 

Touching on the semantics of -cOOre, each object (instance) is associated
with an unique resoure. Each Tasks, methods (for Root also Idle) execute as
a critical section (claiming the resource). This gives us:
- Race free execution in a concurrent setting (similar to sychronize in Java).
- Serialized execution, allowing the observable behavior (ordering of side- 
effects to be precisley defined in the program model).

Since Idle and the task t1 belongs to the same object, they may and will not
run concurrenlty. That is fine in this specific case, but may not in others. 

Concurrency can always be ensured as long as the sender and receiver belongs
to different object (instances), as we will see in the next example:

-------------------------------------------------------------------------------
// CEx3.coore
// Per Lindgren (C) 2014
//
// Multiple objects
class R<> {
    int x := 0;
    int y := 0;
    
    Task t1 () {
        RT_printf("task1 R claimed, point is (%d,%d)\n", x, y);
    }
    
    Task t2 () {
        x := 1;
        RT_printf("task2 R claimed\n");
        RT_sleep(5);
        y := 1;
        RT_printf("task2 R released\n");
    }      
}

class Root<> { 
    R<> r;
    Reset {
        RT_printf("User reset\n");
        async before 9 s r.t2();
        async after 1 s before 10 s r.t1();
    } 
}
-------------------------------------------------------------------------------
Where as shared data in the -core language (and typical thread/task libraries)
has to be manually protected, the object structure or -cOOre gives automatic 
protection.

The instance variables (x,y) are given their intiatial values direclty
in the object instation (in fact statically by the compiler).

The same timing semantics as for -core applies to the -cOOre program.
Let look a bit closer at object instantiation, CEx3.coore:
-------------------------------------------------------------------------------
// CEx4.coore
// Per Lindgren (C) 2014
//
// Static communication (callback) structure
class R<int ri> {
    void fun(int i) {
        RT_printf("task%d R claimed : R.ri = %d\n", i, ri);
        RT_sleep(5);
        RT_printf("task%d R released\n", i);        
    }
     
    Task rt () {
        RT_printf("task rt R.ri = %d \n", ri);
    } 
}

class T<int i, void (int) fun> {
    Task tt () {
        RT_printf("task%d\n", i);
        fun(i);
    }
}

class Root<> { 
    R<10> r;
    T<2, r.fun> t2;
    T<3, r.fun> t3;
    
    Reset {
        async t2.tt(); // task2
        async t3.tt(); // task3
        async after 1 s r.rt();
    } 
}
-------------------------------------------------------------------------------
Unlike traditional OO languages, classes are paramtrised by arguments for the
instantitation (type parameters might come later..)

In the example the object r (of type R), is instantiated with the argument
<10> which matches the <int ri> of the class declaration. The formal class 
parameters becomes available as constant expressions (for primitve typed 
parameters) or method references to the class members and the initintial 
assignments of constants. This allows the backend tool (ultimately the C) 
compiler to inline the constant expressions, thus parametrisation comes for
free from an implementational standpoint.

Currently the compiler does not implement any type checking, but mistyping 
eventually turns up as compilation errors. (Type checking will be introduced 
during the Compiler Construction course and implemented in the compiler.)

Currently, only primitive types and methods are allowed as class parameters,
exentions to Tasks, and complete object interfaces are projected.

As already mentioned, to further increase fexlibility one can think of 
extentions to allow for type paramters, mechanisms for interitance etc.

The instantiaion mechansim statically spans, instantiates and specializes 
the complete set of objects defined by the program direclty at compile time.
In particular, even complex callback patterns can be expressed in a clear
and succint manner as shown in exmple CEx5.coore:
-------------------------------------------------------------------------------
// CEx5.coore
// Per Lindgren (C) 2014
//
// Mutually dependent instances can be created without dynamic installation.
// Potential deadlock may occur in cases of mutual synchrnoous calls.
class R<int my_id, void (int) other_fun> { 
    void fun(int from_id) {
        RT_printf("in fun task %d, from task %d\n", my_id, from_id);
    } 
    
    Task t () {
        RT_printf("task %d\n", my_id);
        RT_sleep(1);
        other_fun(my_id);
    }    
}

class Root<> { 
    R<1, r2.fun> r1;
    R<2, r1.fun> r2;
    
    Reset {
        async r1.t(); // task1
        async r2.t(); // task2
    } 
}
-------------------------------------------------------------------------------
The object instance r1 refers to r2.fun, while r2 refers to r1.fun. After reset
the two task instances (assyncrounous massages) r1.t and r2.t() are released
and will run in a concurrent. Under bare metal execution the use of SRP based
scheduling gurantee deadlock free schdeuling, however the thread based run-time
system will be exposed to potential deadlock (as in this examples).

However, contrary to typical thread based programming APIs and libraries our 
language based approach allows the compiler (rtfm-core) to detect and report
the the issue, and even give visual feedback on the task/resource pattern that
is causing the problem.

In addition to the already mentioned opprtunities for improvements and 
extensions, language support for dynamic object instantiation is on the list.
This will allow for systems with dynamic and mixed static/dynamic behavior to
be expressed in the same languge, and offer opportunities to reasoning about
robustness, etc. form a language perspective.

Word from the author.
The -cOOre language resembles the Concurrent Reactive Object (CRO) model that
underpins the Timber and TinyTimber languages. Whereas, Timber is a 
fully fledged language (with a functional expression layer), static analysis of  
Timber programs has shown tricky (in fact no anaylyses whatsover has been 
implemented as of yet). Still we found an apatite for the CRO mdoel as a means
to specify and implement concurrent systems. From a practical perspective we
implementd a C-API (to a CRO based run-time system) in terms of macros for
object instantiation and syncronous/asyncronous communication. 

In this context RTFM paves a middle ground in between the Timber language (as 
found to be too generic generic to reason on in practise), and TinyTimber
C-API which clearly is too low-level and semanitaclly relaxed to argue on.

The design decisions taken aims at providing execuatbles on par or better than
hand written code. In fact, we challange anyone to write concurrent code by
hand in any langue, under any run-time or kernel, and we are prepared to trade
punches and goto clich without fear of being knowcked or tapped out!

-------------------------------------------------------------------------------

Section E) Run-time systems
This section describe the usage and design of:
PTCORE      : A run-time system for pthread platforms (OSX/Linux, etc.)
WINCORE     : A run-time system for Win32 platforms (WinXP/Win7/Win8, etc.)

E.1) PTCORE Usage, and options.
The PTCORE run-time uses the pthread library for execution onto POSIX based
platforms, and has been adopted and tested under OSX 10.9.4 and Ubuntu (debian)
Linux, 12.04/14.04. It's likely to compile and run under similar 
distributions. In section E.2 we will further discuss the requirements
put by the design of PTCORE.

PTCORE is distributed either as a tarball or from archive, having the same
basic catalogue structure. The given structure can be altered at will, and
is used only for the compilation (i.e., has no meaning during run-time).

The structure is a follows:
PTCORE
Application/augotgen.c (the auto generated C file is assumed here)
RTFM-RT/RTFM-PT.c      (the run-time implementation)
RTFM-RT/RTFM-PT.h      (the basic run-time API)
RTFM-RT/RTFM-RT.h      (the real-time extension to the run-time API)
RTFM-SRC/Ex1.core...   (a set of examples)

An executable i built by simply run
gcc RTFM-PT.c -lpthread 
(the RTFM-PT.c includes the necessary headers and autogen.c)

The PTCORE run-time system currently supports enabling the following options 
given at compile time -D (options can be arbitrarily combined)

TRACE       to trace the interaction between application and run-time system
TRACE_OS    to trace the interaction between run-time system and OS
TRACE_TIME  to trace the current time for other traces
            (will have no effect if both TRACE and TRACE_OS are disabled 
WARN_DL     run-time verification, reporting deadline over-run
ABORT_DL    run-time verification, aborting on deadline over-run

Tracing options are provides detailed information both on the -core program
behaviour as such, but can also be used for getting a deeper understanding
of the run-time system design and implementation. 

The WARN_DL/ABORT_DL options are giving feedback on the timely properties
of the -core program as run under best effort by the PTCORE run-time system.
 
It is possible to link with (any) other C code or library, but -core 
programs are compiled monolithically. However, -core programs may include
other -core files as shown in the examples (section A).

Monolithic compilation facilitates code generation in the -core compiler
(side-stepping the need to define an object-code format for -core).

Moreover, it allows the C compiler (backend) to optimise -core code as a 
whole (circumventing the need for link time optimisation, at least
for the -core parts).

For now, PTCORE has only been tested under gcc, but both CompCert C 
(ccomp) and LLVM (clang) compilation should be feasible with minor 
modifications to the code-generation and run-time system implementation.


E.2) PTCORE design.
PTCORE has been designed to fulfil the following purposes:
- To provide an easy in-step to -core programming, the compilation cycle
from -core program to OSX/Linux executable is typically < 1s. This allows
the programmer to experiment with the language without being concerned with
low-level details of an embedded platform. (Build cycles are typically
more complex, involving the downloading to/flashing of target, observing
stdoutput, typically involves multiple connections/terminals, etc, etc.)

- To provide an alternative to traditional thread based libraries for
concurrent programming in C. Using -core/PTCORE the programmer is required
no knowledge of threads, and can focus directly on the problem to be solved.
Moreover, the -core compiler gives feedback on potential deadlocks directly
derived from analysing the input program. A program that passes without
warning will be free of deadlocks during execution by PTCORE. In comparison
thread libraries (pthreads/boost etc), leaves dead locks at the hand of
the programmer. In case the programmes cannot guarantee the program/model 
to be free of deadlocks, this has to be handled (by the programmer) 
gracefully (by implementing fallback code managing each potential deadlock).

- As a basis for researching multi-core scheduling. Already today PTCORE
provides a unique solution to multi-threaded programming. All tasks are
instantiated at compile time. This allows all costly memory management
(buffer allocations) thread creation etc. to be performed before executing 
the Reset. Hence a system, that is able to start, will never fail due
to the depletion of resources. (During run-time the PTCORE requires 0 bytes
of additional ram!). 

In the following we will outline the basic design of the PTCORE run-time.
E.2a) Outset from -core and the rtfm-core compiler
1) Tasks equals threads
A -core program is fully specialised w.r.t., task instances and functions.
This allows for a 1-1 mapping in between threads and tasks in the system.
Each task instance is associated with a (relative) deadline. The -core 
compiler assigns logic priories to the task instances according to
their deadline (shorter deadline, higher priority).

2) Resources equals (named) critical sections
For a -core program, the resource ceilings are statically computed. 
I.e., for each critical section S, the ceiling of S is equal to the highest
priority of all tasks that access S.

3) Under the assumption that tasks meet their deadline (the system is 
schedulable) and the inter-arrival of tasks are larger then their 
deadline, each message requires only a single buffer element.
All buffers are generated by the -core compiler, and allocated as (static)
heap elements by the C-code linker.

E.2b) PTCORE implementation
The outsets for run-time system implementation given in E.2a) allows
for a minimalistic and efficient design of PTCORE.

1) Each task instance amounts to a thread created with according (static) 
priority. PTCORE deploys pthread FIFO based scheduling. This allows
higher priority tasks to execute preemptively to lower priority tasks 
and works over multiple CPUs. This ensures that the (non-blocked) threads/tasks
with highest priority in the system are executed. 
(FIFO scheduling is non-time sliced, and is the closest to real-time
you get under pthreads).

2) Each resource/critical section amounts to a mutex.
Priority inversion is the case when 
    - a low priority task A holds a resource preventing a 
    - high priority task C form execution, 
    - while a task B with prio A<B<C executes in favour of A.
Pthreads provides among the jungle of primitives and options a means to 
enforce ceiling protocols on the mutexes. In PTCORE we use this feature
to assign a static ceiling to each mutex (resource/critical section).
Hence, as soon as a task enters a critical section, it will run at the
priority of the resource ceiling, thus the problem of priority inversion
is avoided.

3) Under the assumption that E.2a-3) holds, the message passing can be done
without inferring any additional locks (mutexes) on the message buffers.
We perform run-time verification, the ABORT_DL discards an invalid system
during execution, while WARN_DL presents a warning. Without any options
an over-run might pass without the user's attention. To this end, the 
run-time system is designed such to provide a robust solution (discarding
any message causing a buffer). However, in case of overload, in the current 
implementation, only timing information not actual message data is protected 
from race.

4) Thread life cycle.
Each thread is created before the system Reset is executed. 

Reset and Idle are executed as the main thread of the process. This allows
the interaction to badly written (legacy) libraries requiring main thread
hooks, to be setup in Reset and managed in Idle. In this way, PTCORE is
complete w.r.t., POSIX, Reset and Idle may perform ANY system call. 
I.e, any application or even scheduler that can be written under POSIX will 
work in collaboration with PTCORE without the need of ANY adjustments of the
PTCORE run-time.

Each thread is given its task id as argument for creation, through witch
it access the following static structures:

generated by -core compiler
// id
// 0    reset task
// 1    idle 
// ...  application tasks
int entry_prio[] = {0, 0, ...}; 
ENTRY_FUNC entry_func[] = {user_reset, user_idle, ..., ENTRY_NR};

and internal in the PTCORE (ENTRY_NR known after including autogen.c)
RTFM_time       base_line[ENTRY_NR];
RTFM_time       dead_line[ENTRY_NR];
RTFM_time       new_base_line[ENTRY_NR];
RTFM_time       new_dead_line[ENTRY_NR];
pthread_mutex_t res_mutex[RES_NR];
sem_t*          pend_sem[ENTRY_NR];
pthread_mutex_t pend_count_mutex[ENTRY_NR];
int             pend_count[ENTRY_NR] = { 0 };

The thread/task handler is implemented as follows
void *thread_handler(void *id_ptr) {
    int id = *((int *) id_ptr);
        while (1) {
        s_wait(pend_sem[id]);
        // consume the semaphore (decrement its value)
        RTFM_time offset;
        m_lock(&pend_count_mutex[id]);
        {   // inside lock of the counter
            pend_count[id]--; // may not be atomic, hence needs a lock
            // for good measure we work on the timing information under the lock
            base_line[id] = new_base_line[id];
            dead_line[id] = new_dead_line[id];
            RTFM_time cur_time = time_get();
            offset = base_line[id] - cur_time;
        }
        m_unlock(&pend_count_mutex[id]);
        time_usleep(offset);
        entry_func[id](id); // dispatch the task
#ifdef ABORT_DL
        if (over_run(id)) {
            fprintf(stderr, "Aborting on failing to meet deadline!\n");
            exit(EXIT_FAILURE);
        }
#elif WARN_DL
        over_run(id);
#endif
    }
    return NULL;
}

the actual execution the task is performed by entry_func[id], which is
an auto-generated C-code for the task instance, that passes on the arguments
to (a potentially inlined) task implementation, e.g.,

void entry_reset_t_0(int RTFM_id) {
    reset_t_0(RTFM_id, arg_reset_t_0.i); // (inlined) call to the task (function)
}

void reset_t_0(int RTFM_id, int i){ // function implementation for task:reset_t_0
    printf("task t %d\n", i);
}

The structs for holding the message is auto-generated as follows:
typedef struct {int i;} ARG_reset_t_0; // type definition for argument
ARG_reset_t_0 arg_reset_t_0;           // instance for argument

(All data structures, functions etc. are properly prototyped such 
to pass compilation (-wall, C99) without warnings.)

A corresponding async message (triggering this task) looks as follows.

..
arg_reset_t_0 = (ARG_reset_t_0){75*(2+1)}; 
RTFM_pend(0, max_int, RTFM_id, reset_t_0_nr);
.. (Example corresponds to Ex1b.core)

Notice, that passing around the RTFM_id is done only to allow for tracing 
(of the sender) and is omitted when generation code for the ultra-light weight 
RTFM-Kernel. However in the context of threaded hosts each call to the 
underlying OS/library will likely add overhead orders of magnitude larger than
passing an extra parameter.

The implementation of RTFM_pend is as follows
void RTFM_pend(RTFM_time a, RTFM_time b, int f, int t) {
    int lcount;
    m_lock(&pend_count_mutex[t]);
    {   // inside lock of the counter
        lcount = pend_count[t];
        if (lcount == 0) {
            DPT("RTFM_pend   :pend_count[%d]++", t);
            pend_count[t]++; 
            new_base_line[t] = RT_time_add(base_line[f], a); 
            new_dead_line[t] = new_base_line[t] + b;
        }
    }
    m_unlock(&pend_count_mutex[t]);

    if (lcount == 0) { // just a single outstanding semaphore
        s_post(pend_sem[t]);
    } else { // discard message
    }
} 

The handling of resources/mutexes, is straightforward.
Each resource mutex is created with it's ceiling priority.
On entering a critical section, code is auto-generated that locks
the mutex, and on exit a critical section the auto-generated
code unlocks the mutex. 

Under PTCORE, the run-time is implemented as potentially inlined functions
(as we compile the run-time and application together inlining is possible
without fragile link time optimisation). (The RTFM-Kernel API is defined
completely as macros, and hence the RTFM-Kernel is fully inlined, i.e.,
during run-time there is no -Kernel, just the application!)

Future improvements.

1) Stack memory.
For now stack is allocated to default size, but this can be improved on by 
taking the maximum stack required for each task into consideration. 
(gcc -fstack-usage provides this information on a aper function basis, 
-core Funcs call graph is known in the -core compiler, and gcc can report
on the C-call graph (as long as function pointers are not used).

2) Robustness under overload.
Full protection from races on message data can be implemented by allowing
the sender to reject the message if there is already an outstanding 
message. In this way, the mutex inside the thread_handler and
RTFM_pend function can be completely omitted.

3) Deadlock free execution under potential deadlocks.
Work in progress investigates the use of analysis to identify regions
of potential deadlock, and infer "super" locks such that only one
task/thread my enter a danger zone. Already today danger zones are 
reported visually to the end user (as cycles in the dependency graph).
Solving this problem will greatly facilitate concurrent programming
in threaded environments, and may be exactly what we all been waiting for!

4) Buffering of outstanding messages.
The timing semantics for -core currently restricts async messages to single
buffered elements. This may pose a limitation whenever a periodic task emits
messages with a baseline offset (after). In this case we should allocate
a buffer of length after/period to accommodate for the outstanding messages.
Sufficient information to pursue required analysis is present in the -core
model, but the required analysis, code generation and run-time implementation
still remains.

5) Handling of externally caused exceptions.
While the first three improvements are low hanging fruit the 5th is challenging.
Exception handling in most (of not all) languages and models, requires the
raising and handling the exception from within the same context. (Typically 
this amounts to the same thread or task.) Handling of exceptions emitted
externally (e.g., from the run-time system, some other task/thread) is if all
possible, limited supervisory actions, like killing the thread under POSIX.
We currently seek a generic representation for exceptions in the -core language,
and ways to implement it in the run-time system(s). Under pthreads/POSIX signal
handling reflects the commonly limited exception handling (where operations
in signal handlers are severely crippled). Onto bare metal, we are free to
manipulate the stack, and will likely be the target for our first implementation
attempts. 


Word from the author:
PTCORE is simple in design and implementation in comparison to pthread based 
libraries/wrappers like boost. The implementation uses and relies on only 
a very limited subset of the flourishing and blunted pthread library. The
simple design makes it possible to argue on correctness and efficiency.
Libraries like boost, still requires lots of cooperation of the user, 
you need to understand boost (and ultimately the pthreads themselves) to
correctly use threads in C. Under -core/PTCORE this is NOT the case. The
programmer can think in terms of tasks and critical sections, and can 
focus completely on solving the problem at hand, not on how to code for
a solution (or even worse, set of solutions) provided by boost or native
threads. We argue that the expressiveness of -core (and the PTCORE run-time)
is sufficient to expressing most application level functionality, and
as Reset and Idle are implemented in the main thread of the process, we
suffer no loss of generality to native pthreads (-core/PTCORE is complete)
w.r.t., POSIX programming.

The future improvements (state above) will take PTCORE to a new level,
where no existing library based solution can compete. (You need 
language support for static deadlock protection, unless you rely on
deep cooperation by the programmer, or byte-code based solutions 
for which analysis can be performed on). Also w.r.t., to library 
based solutions, we strongly believe that our -core model will infer
(by nature) much more concurrency (and hence potential parallelism)
than library based solutions (where the user must take the conscious
decision to explicitly defer computations to tasks, and weight that
to the overhead of the library and the OS). In our case, it is up
to the compiler to assess the pros-and cons-. Any async, (given 
deadlock free execution) can semantically be executed synchronously (
as long as it does not transitively refer to the sender). Hence, these 
delicate decisions on whether or not to create a task, will no longer 
be a burden put to the programmer. The ONLY thing the programmer needs 
to consider is wether he/she needs the result of an operation (function)
now (sync) or not (async), knowing that a both correct and  efficient 
solution will be derived byt the compiler and run-time.

Assessing hard real-time requirements under a hosting thread based OS
is to my believe not possible and will never be! The mere complexity
of threads and their implementation onto modern multi-core platforms 
goes far beyond any reasoning. However, this does not preclude the 
implementation of robust applications using threads as a vehicle for 
scheduling, given proper run-time verification. To this end -core 
programs carry the timing information in a verifiable way. With
an exception mechanism at hand that allows for external exceptions, 
novel methods for run-time verification may developed to enforce 
robustness without requiring the programmer to manually consider
cases of buffer over-runs, etc.

-core and PTORE are still at early stages of development (3 months
and ticking). However results are already at your hands. Hope you will 
hop on and enjoy the ride.

/Per Lindgren, founder of RTFM-lang August 2014
 
E.3) WINCORE design.
Andreas, I fully trust you on this one!!!!

